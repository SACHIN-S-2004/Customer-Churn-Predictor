<div align="center">
  
# ğŸ“‰ Customer Churn Predictor
ğŸš€ **ML-Powered Customer Retention Intelligence**

![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-ML-orange?style=for-the-badge&logo=scikit-learn)
![Flask](https://img.shields.io/badge/Flask-Web_App-green?style=for-the-badge&logo=flask)
![Bootstrap](https://img.shields.io/badge/Bootstrap-UI-purple?style=for-the-badge&logo=bootstrap)
![Chart.js](https://img.shields.io/badge/Chart.js-Visualization-orange?style=for-the-badge&logo=chartdotjs)

Identify whether the customers are likely to stay or churn using Machine Learning â€” instantly and accurately
</div>

------------------------------------------------------------------------

## ğŸ“Œ Project Overview

The **Customer Churn Predictor** is an end-to-end **Machine Learning +
Web Application** designed to help businesses identify customers who are
likely to leave (churn).

Unlike basic classifiers, this project: 
- Predicts **Churn / No Churn**
- Shows **confidence percentage (%)**
- Visualizes prediction confidence using **interactive graphs**
- Uses a **production-ready ML pipeline**

------------------------------------------------------------------------

## âœ¨ Key Features

-   âœ… Churn / No Churn prediction
-   ğŸ“Š Probability-based confidence score
-   ğŸ“ˆ Interactive visualization (Chart.js)
-   ğŸ¨ Production-grade Bootstrap UI
-   ğŸ§  End-to-end ML pipeline (preprocessing + model)
-   ğŸ”’ Safe handling of unseen categorical values

------------------------------------------------------------------------

## ğŸ–¼ï¸ Sample Screenshots

<div align="center">

### ğŸ’» Webpage - Responsive Design

![alt text](sampleScreenshots/Screenshot%202026-01-18%20122617.png)

### ğŸ“Š Prediction Results

![alt text](sampleScreenshots/Screenshot%202026-01-18%20124140.png)

![alt text](sampleScreenshots/Screenshot%202026-01-18%20124607.png)

*Real-time classification results*

</div>

------------------------------------------------------------------------

## ğŸ§  Machine Learning Workflow

### ğŸ”¹ Data Preprocessing

Handled **inside the pipeline**: - One-Hot Encoding for categorical features
- Numerical features passed directly
- `handle_unknown="ignore"` for robust inference

### ğŸ”¹ Features Used

-   Age
-   Gender
-   Tenure
-   Usage Frequency
-   Support Calls
-   Payment Delay
-   Subscription Type
-   Contract Length
-   Total Spend
-   Last Interaction

------------------------------------------------------------------------

## ğŸ§ª Models Trained & Evaluated

During experimentation in the Jupyter Notebook (`.ipynb`), the following
**supervised classification models** were trained and evaluated:

### 1ï¸âƒ£ Logistic Regression

-   Used as a **baseline model**
-   Fast and interpretable
-   Performs well on linearly separable data
-   Limited in capturing complex, non-linear relationships

### 2ï¸âƒ£ Random Forest Classifier

-   Ensemble-based model using multiple decision trees
-   Handles non-linear patterns well
-   Robust to outliers and noise
-   Provides good performance but can be less stable for probability
    estimates

### 3ï¸âƒ£ Gradient Boosting Classifier

-   Sequential ensemble model
-   Focuses on correcting previous model errors
-   Excellent performance on structured/tabular data
-   Produces reliable probability scores

------------------------------------------------------------------------

## ğŸ† Model Selection

After comparing all trained models, **Gradient Boosting Classifier** was
selected as the final model.

### ğŸ” Why Gradient Boosting?

| Criteria | Gradient Boosting | Random Forest | Logistic Regression |
|----------|-------------------|---------------|---------------------|
| Non-linear learning | âœ… Excellent | âœ… Good | âŒ Limited |
| Probability quality | âœ… High | âš ï¸ Medium | âš ï¸ Medium |
| Tabular data performance | â­â­â­â­ | â­â­â­ | â­â­ |
| Business reliability | âœ… Strong | âœ… Good | âš ï¸ Basic |

### âœ… Final Choice

â¡ï¸ **Gradient Boosting Classifier with a Scikit-learn Pipeline**

This choice ensures: 
- Higher predictive accuracy
- More reliable confidence percentages
- Better generalization on real-world customer data

------------------------------------------------------------------------

## ğŸŒ Web Application Overview

### ğŸ–¥ï¸ Frontend

-   Bootstrap-based dashboard UI
-   Dropdowns for categorical features
-   Responsive & clean layout
-   Doughnut chart for probability visualization

### âš™ï¸ Backend

-   Flask server
-   Loads trained ML pipeline (`.pkl`)
-   Uses `predict_proba()` for confidence scoring

### ğŸ“Š Output

-   **Churn ğŸš¨ / No Churn âœ…**
-   Confidence percentage (%)
-   Interactive visual graph

------------------------------------------------------------------------

## ğŸš€ How to Run the Project

### Clone the repository
``` bash
git clone https://github.com/your-username/Customer-Churn-Predictor.git
```

### Navigate to project directory
```bash
cd Customer-Churn-Predictor
```

### Install dependencies
```bash
pip install -r requirements.txt
```

### Run the Flask app
```bash
python app.py
```

Open in browser:

    http://127.0.0.1:5000

------------------------------------------------------------------------

## ğŸ“Š Sample Output

    Prediction: No Churn âœ…
    Stay Probability: 86%
    Churn Probability: 14%

------------------------------------------------------------------------

## ğŸ“Œ Business Value

-   Identify high-risk customers early
-   Enable proactive retention strategies
-   Reduce customer churn
-   Support data-driven decision making

------------------------------------------------------------------------

## ğŸ‘¨â€ğŸ’» Author

**Sachin Suresh**
Machine Learning & Full-Stack Developer

â­ *If you find this project useful, consider giving it a star!*
